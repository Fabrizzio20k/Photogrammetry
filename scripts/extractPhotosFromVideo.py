import cv2
import os
import numpy as np
from shutil import rmtree
from tqdm import tqdm


def calculate_frame_sharpness(frame):
    """
    Calcula la nitidez de un frame usando la varianza del Laplaciano
    Valores m√°s altos = m√°s n√≠tido
    """
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
    return laplacian_var


def calculate_frame_quality_score(frame):
    """
    Calcula un score de calidad general del frame considerando m√∫ltiples factores
    """
    # 1. Nitidez (varianza del Laplaciano)
    sharpness = calculate_frame_sharpness(frame)

    # 2. Contraste (desviaci√≥n est√°ndar de los p√≠xeles)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    contrast = np.std(gray)

    # 3. Exposici√≥n (evitar sobre/sub exposici√≥n)
    # Penalizar si hay demasiados p√≠xeles muy oscuros o muy claros
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    total_pixels = frame.shape[0] * frame.shape[1]

    # Porcentaje de p√≠xeles muy oscuros (0-20) y muy claros (235-255)
    dark_pixels = np.sum(hist[0:21]) / total_pixels
    bright_pixels = np.sum(hist[235:256]) / total_pixels

    # Score de exposici√≥n (mejor cuando hay pocos p√≠xeles en extremos)
    exposure_score = max(0, 1 - (dark_pixels + bright_pixels) * 2)

    # 4. Informaci√≥n/Entrop√≠a (m√°s informaci√≥n = mejor)
    hist_norm = hist.flatten() / total_pixels
    hist_norm = hist_norm[hist_norm > 0]  # Evitar log(0)
    entropy = -np.sum(hist_norm * np.log2(hist_norm))
    entropy_score = min(entropy / 8.0, 1.0)  # Normalizar a 0-1

    # Score compuesto
    quality_score = (
        min(sharpness / 500, 1.0) * 0.4 +      # Nitidez (normalizada)
        min(contrast / 60, 1.0) * 0.3 +        # Contraste (normalizada)
        exposure_score * 0.2 +                  # Exposici√≥n
        entropy_score * 0.1                     # Informaci√≥n
    )

    return quality_score, {
        'sharpness': sharpness,
        'contrast': contrast,
        'exposure_score': exposure_score,
        'entropy_score': entropy_score
    }


def calculate_frame_similarity(frame1, frame2):
    """
    Calcula la similitud entre dos frames usando histogramas
    Retorna valor entre 0 (muy diferentes) y 1 (id√©nticos)
    """
    # Convertir a HSV para mejor comparaci√≥n
    hsv1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)
    hsv2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)

    # Calcular histogramas
    hist1 = cv2.calcHist([hsv1], [0, 1, 2], None, [
                         50, 60, 60], [0, 180, 0, 256, 0, 256])
    hist2 = cv2.calcHist([hsv2], [0, 1, 2], None, [
                         50, 60, 60], [0, 180, 0, 256, 0, 256])

    # Normalizar histogramas
    cv2.normalize(hist1, hist1, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    cv2.normalize(hist2, hist2, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)

    # Calcular correlaci√≥n
    correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
    return correlation


def calculate_optimal_frame_count(duration_seconds, fps, min_frames=10, max_frames=200):
    """
    Calcula el n√∫mero √≥ptimo de frames basado en la duraci√≥n del video
    """
    # Reglas heur√≠sticas para fotogrametr√≠a
    if duration_seconds <= 5:
        optimal = max(min_frames, min(duration_seconds * 3, max_frames))
    elif duration_seconds <= 15:
        optimal = max(min_frames, min(duration_seconds * 2, max_frames))
    elif duration_seconds <= 30:
        optimal = max(min_frames, min(duration_seconds * 1.5, max_frames))
    elif duration_seconds <= 60:
        optimal = max(min_frames, min(duration_seconds * 1, max_frames))
    else:
        optimal = max(min_frames, min(duration_seconds * 0.8, max_frames))

    return int(optimal)


def extract_frames_from_video_smart(video_path, output_folder="images", num_frames=None,
                                    quality=95, min_sharpness=None, max_similarity=0.85,
                                    quality_threshold=None, force_vertical=True,
                                    analysis_sample=0.1, debug_mode=False):
    """
    Extrae frames de un video con filtrado inteligente de calidad

    Args:
        video_path: Ruta del video
        output_folder: Carpeta de salida
        num_frames: N√∫mero de frames objetivo (None para c√°lculo autom√°tico)
        quality: Calidad JPEG (1-100)
        min_sharpness: Nitidez m√≠nima requerida (None para c√°lculo autom√°tico)
        max_similarity: Similitud m√°xima entre frames consecutivos (0-1)
        quality_threshold: Umbral m√≠nimo de calidad general (None para c√°lculo autom√°tico)
        force_vertical: Forzar orientaci√≥n vertical
        analysis_sample: Fracci√≥n del video a analizar para estad√≠sticas (0.1 = 10%)
        debug_mode: Mostrar informaci√≥n detallada de debug
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    else:
        rmtree(output_folder)
        os.makedirs(output_folder)

    video = cv2.VideoCapture(video_path)
    if not video.isOpened():
        raise ValueError(f"No se pudo abrir el video: {video_path}")

    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = video.get(cv2.CAP_PROP_FPS)
    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps if fps > 0 else 0

    print(f"üé• Video: {os.path.basename(video_path)}")
    print(f"üìê Dimensiones: {width}x{height} p√≠xeles")
    print(f"‚è±Ô∏è  Duraci√≥n: {duration:.2f} segundos")
    print(f"üéûÔ∏è  Total frames: {total_frames}, FPS: {fps:.1f}")

    if total_frames <= 0:
        raise ValueError("No se detectaron frames en el video")

    # Calcular n√∫mero √≥ptimo de frames si no se especifica
    if num_frames is None:
        num_frames = calculate_optimal_frame_count(duration, fps)
        print(f"üßÆ Frames objetivo calculado autom√°ticamente: {num_frames}")
    else:
        print(f"üéØ Frames objetivo especificado: {num_frames}")

    # FASE 1: An√°lisis de calidad en una muestra del video
    print("\nüìä Fase 1: Analizando calidad del video...")

    sample_size = max(10, int(total_frames * analysis_sample))
    sample_indices = np.linspace(0, total_frames - 1, sample_size, dtype=int)

    sharpness_values = []
    quality_scores = []

    for frame_idx in tqdm(sample_indices, desc="Analizando muestra"):
        video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        success, frame = video.read()

        if success:
            if force_vertical and frame.shape[1] > frame.shape[0]:
                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)

            sharpness = calculate_frame_sharpness(frame)
            quality_score, _ = calculate_frame_quality_score(frame)

            sharpness_values.append(sharpness)
            quality_scores.append(quality_score)

    if not sharpness_values:
        raise ValueError("No se pudieron analizar frames del video")

    # Estad√≠sticas de calidad
    avg_sharpness = np.mean(sharpness_values)
    std_sharpness = np.std(sharpness_values)
    min_sharpness_found = np.min(sharpness_values)
    max_sharpness_found = np.max(sharpness_values)
    avg_quality = np.mean(quality_scores)
    std_quality = np.std(quality_scores)
    min_quality_found = np.min(quality_scores)
    max_quality_found = np.max(quality_scores)

    if debug_mode:
        print(f"   üîç Debug - Estad√≠sticas de nitidez:")
        print(
            f"      Min: {min_sharpness_found:.1f}, Max: {max_sharpness_found:.1f}")
        print(f"      Promedio: {avg_sharpness:.1f} ¬± {std_sharpness:.1f}")
        print(f"   üîç Debug - Estad√≠sticas de calidad:")
        print(
            f"      Min: {min_quality_found:.3f}, Max: {max_quality_found:.3f}")
        print(f"      Promedio: {avg_quality:.3f} ¬± {std_quality:.3f}")

    # Ajustar umbrales basados en las caracter√≠sticas del video (m√°s permisivos)
    if min_sharpness is None:
        # Usar percentil 25 en lugar de promedio - desviaci√≥n
        adaptive_min_sharpness = np.percentile(sharpness_values, 25)
    else:
        adaptive_min_sharpness = min_sharpness

    if quality_threshold is None:
        # Usar percentil 25 para ser m√°s permisivo
        adaptive_quality_threshold = np.percentile(quality_scores, 25)
    else:
        adaptive_quality_threshold = quality_threshold

    print(
        f"   üìà Nitidez - Min encontrada: {min_sharpness_found:.1f}, Promedio: {avg_sharpness:.1f}")
    print(f"   üéØ Usando umbral de nitidez: {adaptive_min_sharpness:.1f}")
    print(
        f"   üèÜ Calidad - Min encontrada: {min_quality_found:.3f}, Promedio: {avg_quality:.3f}")
    print(f"   üéØ Usando umbral de calidad: {adaptive_quality_threshold:.3f}")

    # FASE 2: Extracci√≥n inteligente de frames
    print(f"\nüéØ Fase 2: Extrayendo frames con filtrado de calidad...")

    # Calcular frames candidatos (m√°s de los necesarios para filtrar)
    candidate_multiplier = 3  # Extraer 3x m√°s candidatos para filtrar
    candidate_frames = min(num_frames * candidate_multiplier, total_frames)
    candidate_indices = np.linspace(
        0, total_frames - 1, candidate_frames, dtype=int)

    frame_candidates = []

    for i, frame_idx in enumerate(tqdm(candidate_indices, desc="Evaluando candidatos")):
        video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        success, frame = video.read()

        if not success:
            continue

        if force_vertical and frame.shape[1] > frame.shape[0]:
            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)

        # Calcular m√©tricas de calidad
        sharpness = calculate_frame_sharpness(frame)
        quality_score, quality_metrics = calculate_frame_quality_score(frame)

        # Filtrar por umbrales m√≠nimos
        if sharpness >= adaptive_min_sharpness and quality_score >= adaptive_quality_threshold:
            timestamp = frame_idx / fps if fps > 0 else 0

            frame_candidates.append({
                'frame': frame.copy(),
                'frame_idx': frame_idx,
                'timestamp': timestamp,
                'sharpness': sharpness,
                'quality_score': quality_score,
                'quality_metrics': quality_metrics
            })

    print(f"   ‚úÖ Candidatos de calidad encontrados: {len(frame_candidates)}")

    if len(frame_candidates) == 0:
        print("‚ö†Ô∏è  No se encontraron frames de suficiente calidad. Aplicando umbrales de emergencia...")

        # Umbrales de emergencia mucho m√°s permisivos
        emergency_min_sharpness = np.percentile(
            sharpness_values, 10) if len(sharpness_values) > 0 else 10
        emergency_quality_threshold = np.percentile(
            quality_scores, 10) if len(quality_scores) > 0 else 0.1

        print(
            f"   üö® Umbrales de emergencia - Nitidez: {emergency_min_sharpness:.1f}, Calidad: {emergency_quality_threshold:.3f}")

        for i, frame_idx in enumerate(tqdm(candidate_indices, desc="Re-evaluando con umbrales de emergencia")):
            video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            success, frame = video.read()

            if not success:
                continue

            if force_vertical and frame.shape[1] > frame.shape[0]:
                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)

            sharpness = calculate_frame_sharpness(frame)
            quality_score, quality_metrics = calculate_frame_quality_score(
                frame)

            if debug_mode and i < 10:  # Solo mostrar los primeros 10 para debug
                print(
                    f"      Frame {i}: Nitidez={sharpness:.1f}, Calidad={quality_score:.3f}")

            if sharpness >= emergency_min_sharpness and quality_score >= emergency_quality_threshold:
                timestamp = frame_idx / fps if fps > 0 else 0

                frame_candidates.append({
                    'frame': frame.copy(),
                    'frame_idx': frame_idx,
                    'timestamp': timestamp,
                    'sharpness': sharpness,
                    'quality_score': quality_score,
                    'quality_metrics': quality_metrics
                })

        print(
            f"   ‚úÖ Candidatos con umbrales de emergencia: {len(frame_candidates)}")

    if len(frame_candidates) == 0:
        print("‚ùå A√∫n no se encontraron candidatos v√°lidos. Extrayendo los mejores disponibles...")

        # Como √∫ltimo recurso, tomar simplemente los mejores frames sin filtros
        all_candidates = []
        sample_indices_large = np.linspace(
            0, total_frames - 1, min(500, total_frames), dtype=int)

        for frame_idx in tqdm(sample_indices_large, desc="Evaluando todos los frames disponibles"):
            video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            success, frame = video.read()

            if not success:
                continue

            if force_vertical and frame.shape[1] > frame.shape[0]:
                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)

            sharpness = calculate_frame_sharpness(frame)
            quality_score, quality_metrics = calculate_frame_quality_score(
                frame)
            timestamp = frame_idx / fps if fps > 0 else 0

            all_candidates.append({
                'frame': frame.copy(),
                'frame_idx': frame_idx,
                'timestamp': timestamp,
                'sharpness': sharpness,
                'quality_score': quality_score,
                'quality_metrics': quality_metrics
            })

        # Tomar los mejores frames disponibles
        if all_candidates:
            all_candidates.sort(key=lambda x: x['quality_score'], reverse=True)
            frame_candidates = all_candidates[:min(
                num_frames * 2, len(all_candidates))]
            print(
                f"   üÜò Seleccionados {len(frame_candidates)} mejores frames disponibles")

    if len(frame_candidates) == 0:
        raise ValueError(
            "No se encontraron frames de calidad suficiente en el video")

    # FASE 3: Selecci√≥n final con filtrado de similitud
    print(f"\nüîç Fase 3: Seleccionando mejores frames y filtrando similares...")

    # Ordenar candidatos por calidad
    frame_candidates.sort(key=lambda x: x['quality_score'], reverse=True)

    selected_frames = []
    num_frames_target = min(num_frames, len(frame_candidates))

    for candidate in frame_candidates:
        if len(selected_frames) >= num_frames_target:
            break

        # Verificar similitud con frames ya seleccionados
        is_similar = False
        for selected in selected_frames:
            similarity = calculate_frame_similarity(
                candidate['frame'], selected['frame'])
            if similarity > max_similarity:
                is_similar = True
                break

        if not is_similar:
            selected_frames.append(candidate)

    # Si no tenemos suficientes frames √∫nicos, agregar los mejores restantes
    if len(selected_frames) < num_frames_target:
        # Crear set de IDs de frames ya seleccionados para comparaci√≥n eficiente
        selected_frame_ids = {frame['frame_idx'] for frame in selected_frames}
        remaining_candidates = [
            c for c in frame_candidates if c['frame_idx'] not in selected_frame_ids]
        remaining_needed = num_frames_target - len(selected_frames)
        selected_frames.extend(remaining_candidates[:remaining_needed])

    # FASE 4: Guardar frames seleccionados
    print(
        f"\nüíæ Fase 4: Guardando {len(selected_frames)} frames seleccionados...")

    # Ordenar por timestamp para mantener orden cronol√≥gico
    selected_frames.sort(key=lambda x: x['timestamp'])

    extracted_frames = []
    encode_params = [int(cv2.IMWRITE_JPEG_QUALITY), quality]

    for i, frame_data in enumerate(tqdm(selected_frames, desc="Guardando frames")):
        output_path = os.path.join(
            output_folder,
            f"frame_{i+1:03d}_{frame_data['timestamp']:.2f}s_q{frame_data['quality_score']:.3f}.jpg"
        )

        cv2.imwrite(output_path, frame_data['frame'], encode_params)
        extracted_frames.append(output_path)

        # Debug info
        metrics = frame_data['quality_metrics']
        print(f"   Frame {i+1}: Sharp={frame_data['sharpness']:.0f}, "
              f"Qual={frame_data['quality_score']:.3f}, "
              f"Tiempo={frame_data['timestamp']:.2f}s")

    video.release()

    print(f"\nüéâ Proceso completado:")
    print(f"   üìÅ Frames guardados en: '{output_folder}'")
    print(
        f"   üìä Frames extra√≠dos: {len(extracted_frames)} de {total_frames} totales")
    print(
        f"   üéØ Eficiencia: {len(extracted_frames)/candidate_frames*100:.1f}% de candidatos aprobados")

    return extracted_frames

# Funci√≥n simplificada para uso b√°sico


def extract_frames_smart(video_path, output_folder="images", target_frames=None, debug=False):
    """
    Versi√≥n simplificada con configuraci√≥n autom√°tica y m√°s permisiva
    """
    return extract_frames_from_video_smart(
        video_path=video_path,
        output_folder=output_folder,
        num_frames=target_frames,  # None para c√°lculo autom√°tico
        quality=95,
        min_sharpness=None,  # C√°lculo autom√°tico
        max_similarity=0.9,  # Permitir frames m√°s similares
        quality_threshold=None,  # C√°lculo autom√°tico
        force_vertical=True,
        debug_mode=debug
    )

# Funci√≥n para casos problem√°ticos


def extract_frames_permissive(video_path, output_folder="images", target_frames=None):
    """
    Versi√≥n s√∫per permisiva para videos de baja calidad
    """
    return extract_frames_from_video_smart(
        video_path=video_path,
        output_folder=output_folder,
        num_frames=target_frames,
        quality=95,
        min_sharpness=10,  # Muy permisivo
        max_similarity=0.95,  # Permitir frames muy similares
        quality_threshold=0.05,  # S√∫per permisivo
        force_vertical=True,
        debug_mode=True
    )
